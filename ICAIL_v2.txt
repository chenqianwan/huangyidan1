Value Laden Reasoning, Synthetic Empathy: LLM Performance in Chinese Domestic Violence Adjudication
Abstract

LLMs are rapidly moving from legal assistance to quasi adjudicative roles, where their outputs can shape how vulnerable parties are heard and believed. Yet we still lack rigorous evidence on whether these models reproduce, flatten, or distort the value laden reasoning that Chinese judges deploy in domestic violence disputes, a domain where outcomes often turn on contested narratives, relational norms, and open textured standards such as reasonableness, fault, and protectability. We propose an expert annotated benchmark built from 108 cases from 2023 to 2025, including Supreme People’s Court leading cases, and 540 structured dispute questions spanning abuse characterization, risk and persistence, evidence appraisal, victim blaming, and public morals. We evaluate six dimensions of judicial quality, including subsumption chain alignment and value balancing with empathy. Across models, the dominant stance is protective. Safety and dignity are consistently prioritized, and the best interests of minors are treated as a central axis of discretion. Overt victim blaming is uncommon. The prevailing voice is calm, restrained, and counseling oriented, which can help users articulate risk, organize facts, and seek timely remedies. These strengths make LLMs well suited for front end triage and legal information support. They also have promise as judge facing screening tools in high volume family courts, especially for flagging risk factors and structuring issues. One caution remains. Even when value alignment is strong, authority precision and record fidelity can slip. Use should therefore remain assistant based and procedurally bounded. Our benchmark and code are available at BenchForm.


Keywords: large language models, domestic violence, judicial reasoning, value judgment, benchmark

1 INTRODUCTION

Domestic violence disputes are a stress test for legal AI. The outcomes depend on value judgments, not just rule matching.[]Judges must translate vulnerability, credibility, relational power, and social meaning into legal categories under open textured standards. Therefore, small shifts in reasoning can change who is protected and who is doubted.[] In China, anti domestic violence governance has advanced through statute, judicial interpretation, and interagency instruments, yet proof friction and coordination failures remain common in practice.[] These gaps invite LLMs to act as quasi adjudicative assistants. They do not only summarize facts, they also generate evaluative narratives about fault, risk, protectability, and remedies.[] The promise is scale and consistency. The danger is normative drift that looks like neutral help.[] Value choices can enter through what the model highlights, downplays, or treats as decisive.[] Legitimacy therefore turns on value congruence as much as technical accuracy.[] This is acute in domestic violence cases. A calm, well structured answer can still cause secondary harm if it normalizes coercion or reallocates blame under the label of reasonableness. What we still lack is evidence about how LLM reasoning behaves when judges must integrate doctrine with culturally situated relational concepts.[]
Law is a text based social technology, but its authority rests on institutional practice that stabilizes how texts are invoked and contested. LLMs are also text technologies. That kinship makes it plausible that they could extend legal capacity, and it raises governance stakes as they approach functional parity with lawyers.[] Adoption is already happening. Global firms are purchasing chatbot systems for advisory work.[] Public perceptions matter in this setting. People assess automated legal authority through legitimacy frames, not only performance frames.[] Legal value alignment is harder than general moral alignment. It must cope with normative uncertainty, doctrinal constraints, procedure, and social pluralism. Methods that classify value orientations can map tendencies, but they do not ensure doctrinal discipline or stability across cases.[] The gap shows up in jury like tasks. LLMs can be more consistent than humans, yet still reproduce biases driven by nonevidentiary factors. Sun et al. (2025) show that LLMs can be more consistent than human jurors, yet their judgments still track nonevidentiary factors, which limits readiness for judicial integration. Proposed fixes help, but they do not solve the hardest part.[] Pang et al. (2024) use self dialog training to improve norm learning[], and Feng et al. (2024) pursue case based reasoning to anchor outputs in precedent like patterns.[] These approaches still struggle with disciplined fact weighting under open textured standards. Lacroix (2024) frames this as a problem of normative uncertainty, where fluent language can mask thin justificatory structure.[]
The empathy layer adds another risk. LLMs can generate supportive language at near zero cost, so users may over attribute care.[] Commercial systems explicitly sell this promise with claims like "AI companion who cares" and "always ready to chat when you need an empathetic friend".[] Empathy is not one thing. It includes understanding, affective resonance, and motivational concern.[] The motivational part is exactly where current systems face principled obstacles.[] Humans often avoid empathy because it is effortful and costly.[] LLMs can still infer emotional states and produce fluent responses by pattern learning.[] That makes warmth a weak signal of genuine responsiveness. It matters even more when the output influences legal blame and protection.[] Haugeland captured the structural worry in one line: "The trouble with artificial intelligence is that computers do not give a damn".[]
To address this gap, we introduce DVJUSTICE, a benchmark built from domestic violence decisions in China Judgments Online (https://wenshu.court.gov.cn/) and the Supreme People’s Court 2025 Typical Anti Domestic Violence Cases (https://www.court.gov.cn/zixun/xiangqing/482111.html). We do not target multiple choice items or bar style recall. Prior work already shows rapid gains on exams and classroom style tests. Katz et al. (2023) find GPT 4 level systems can likely pass and rank highly.[] Choi et al. (2023) likewise show passing performance that still resembles a mediocre law student.[] Savelka et al. (2023) show strong performance in concept explanation when a model is augmented with case law. These results matter, but they do not answer our question.[] Domestic violence adjudication is not a closed book test. It is a test of value judgment under uncertainty.
Our goal is different. We evaluate whether an LLM can balance legal norms with relational context and moral stakes. China is a meaningful setting for this test. Chinese judging is neither purely adversarial nor purely inquisitorial.[] Judges apply statutes, but they also justify outcomes in terms of social effects and fairness. This discretion is most visible when doctrine is open textured. It appears in standards like reasonableness, fault, danger, and protectability. It also appears in culturally loaded concepts such as family, endurance, face, and caregiving. Our benchmark is designed to probe that discretionary layer, not to reward fluent summaries.
Besides, we build the dataset from 108 cases. We prioritize decisions with dense reasoning and contested narratives. We include cases endorsed as typical by the Supreme People’s Court. Each document is manually segmented into background facts, keywords, judicial reasoning, and disposition. We do not ask models to draft full opinions. That setup hides failure modes behind verbosity. Instead, each case yields five structured dispute questions. This produces 540 questions. The questions focus on abuse characterization, risk and persistence, evidence appraisal, responsibility attribution, and public morals. We avoid pure fact lookup. We also take leakage seriously. Many LLMs can search the internet. China Judgments Online also restricts access through real name login in many workflows, which raises friction for direct copying. Still, training set memorization remains possible. We therefore paraphrase and de identify the background and outcome sections. We remove names, courts, and docket identifiers. We also reduce overlap with the original phrasing. This forces the model to justify, not to recall. 
Evaluation is done by experienced legal annotators. They score outputs on six dimensions: (a) Normative Basis Relevance, (b) Subsumption Chain Alignment, (c) Key Facts and Issue Coverage, (d) Outcome and Remedy Alignment, (e) Value Balancing and Empathy Alignment, and (f) Impactful Errors. We test several leading systems, including GPT 4o, GPT 5, DeepSeek-R1, DeepSeek-V3, and Qwen-Max, Gemini 2.5 Flash, Claude Opus 4. We also add a meta evaluation setting. It tests whether LLMs can grade legal reasoning with stability. 
Our contributions are as follows. 1. We propose DVJUSTICE, a novel benchmark for measuring value laden adjudication in complex domestic violence cases in China. It consists of structured question answer pairs and a meta evaluation layer. It targets relational norms and public morals reasoning that are central to this domain. It also differs from prior hard reasoning tasks because both sides can be legally defensible and model outputs are long. Inter annotator agreement for the meta evaluations is at least 75 percent across five task settings. 2. We define six quantifiable dimensions that are indispensable for judicial quality in this setting, including normative basis relevance, subsumption chain alignment, key facts and issue coverage with evidence mapping, outcome and remedy alignment, value balancing with empathy, and impactful error severity. We operationalize these dimensions in a scoring rubric that supports automated scoring of LLM outputs and enables systematic benchmarking of state of the art LLMs as evaluators. 3. We conduct qualitative analyses to show how LLMs succeed and fail across the six dimensions. We highlight failure modes that matter most in domestic violence adjudication, where superficial care can mask weak legal warrants and where miscalibrated value judgments can intensify secondary harm.

2 RELATED WORK

LLMs are increasingly used for legal retrieval, judgment prediction, and position understanding, and that trend has pushed research toward building domain specific datasets that can tune models to legal language and doctrine.[] Most existing benchmarks, however, primarily test whether a model can map facts to labels, retrieve similar cases, or pick the best holding from options.[] These tasks are useful, but they under-measure what courts must do in domestic violence disputes: weigh contested narratives, apply open textured standards, and justify protective outcomes in ways that remain socially legitimate. In China, this gap is sharper because adjudication often integrates statutory application with evaluative judgments about risk, fault, protectability, and public morals. Large scale multilingual corpora further expand coverage, yet scale does not guarantee jurisdictional discipline, and it can even increase norm drift when models generalize across incompatible legal cultures.[] Recent surveys therefore frame legal LLM deployment as a governance problem, not only an accuracy problem.[] This matters for AI empathy too. Systems can sound supportive, but legal and ethical analyses stress unresolved risks around confidentiality, neutrality, inclusion, fairness, and mental health, which are precisely where synthetic empathy can obscure harmful social judgment. This motivates our focus on value laden reasoning and synthetic empathy in Chinese domestic violence adjudication, and it frames our evaluation as a test of legal and moral balancing rather than exam style competence.

2.1 Benchmarks for Domestic Violence Cases

In legal practice, large language models are already used to draft and manage documents, reduce turnaround time, and standardize routine client communications.[] This makes them plausible substitutes for parts of lawyer labor, but it does not justify substituting judicial judgment. Domain tuned systems push further by combining specialized corpora with external knowledge structures and multi agent workflows, which can improve format discipline and apparent completeness in service settings.[] At the same time, these models are promoted for decision support tasks such as strategy triage, risk assessment, and outcome forecasting, and existing benchmarks report nontrivial performance on structured targets like labels and extracted fields.[] Practice deployments also emphasize compliance and due diligence triage and chatbot style intake, which primarily improves throughput at early stages.[] Even work on statutory simplification using retrieval and strong models finds the output useful as preliminary support but unreliable as an end to end pipeline, which cautions against claims of adjudicative replacement.[]
The core benchmarking risk is that helpfulness and fluency can be rewarded even when legal reliability fails. Systems may generate answers that users rate as more helpful than humans, while still fabricating facts and inventing legal texts, which is a uniquely dangerous error mode in law.[] Anchoring evaluation in general web sources is also weak, because legal authority is not guaranteed by accessibility, and domain specificity can defeat encyclopedic baselines.[] Process based evaluation therefore argues that legal assistance should be tested as a workflow, including how it elicits user needs and justifies advice, rather than as a single answer.[] Hybrid designs that combine conversational flexibility with structured expert system constraints follow from this logic.[] Recent architectures move in that direction through retrieval augmentation, knowledge graphs, and domain model collaboration, yet they still mainly optimize correctness and coverage, not discretionary value balancing.[] This matters most in domestic violence adjudication, where the hard part is weighing contested narratives, relational power, and protective aims without producing secondary harm, and where legal and ethical analyses highlight unresolved risks around confidentiality, neutrality, inclusion, fairness, and mental health.[]
In addition, in legal reasoning, many benchmarks still reward answer matching more than legally accountable justification. Legal disputes rarely have one correct resolution, especially once they reach litigation or appellate review, so binary accuracy can misstate both difficulty and failure modes.[] This problem is structural in legal QA suites and NLI style datasets, where the task often collapses discretion into a single label or option.[] That design can test vocabulary and issue spotting, but it cannot show whether a model can build a defensible bridge from norms to contested facts. Frontier models also look strong on exam style settings, which signals growing legal knowledge, but it still does not guarantee sound reasoning under open textured standards.[] Some newer benchmarks therefore move closer to judicial writing and adversarial argumentation. They evaluate whether models can support opposing outcomes and whether their citations and warrants remain valid under pressure.[] These findings motivate a stricter framing for domestic violence evaluation. The central question is not whether a model can answer like a student. It is whether it can justify protective judgment without laundering intuition into legal form.
In research on LLM assisted work in value and emotion sensitive settings, legal QA is often framed as an access to justice tool. One line of work shows that a strong model can help de escalate conflict in online dispute resolution by rewriting inflammatory messages and suggesting mediator interventions, which treats language as a lever for procedural fairness.[] Educational studies also show a pattern that matters for domestic violence: models tend to perform better on essay style explanation than on issue spotting in fact rich scenarios, which is exactly where victims need careful framing and legally disciplined care.[] Prompting methods such as chain of thought and IRAC can improve structure and coherence, but the hardest failures still involve applying local law to messy facts.[] Legal practice commentaries reach a similar conclusion: the tool can assist, yet it cannot replace litigation judgment when current law, evidence strategy, and credibility are contested.[] 
At the same time, existing domestic violence datasets largely support detection and prevalence research, not adjudicative reasoning that integrates law, public morals, and relational context.[] Foundational social science work maps DV drivers such as masculinity, patriarchy, culture, and household bargaining, and formal concept analysis clarifies how DV categories travel across settings, but these contributions do not yield benchmarks for legal justification.[] Disagreement about who counts as victim or perpetrator, including male victimization and female perpetration, further shows why moral labeling can distort rather than illuminate legal evaluation.[] Many ML datasets rely on surveys and questionnaires, which scale but can lose realism, while incidence estimation studies face similar limits when they depend on legacy surveys.[] Text based corpora from child welfare records and social media offer more direct behavioral signals, yet they still lack the courtroom perspective on proof, narrative contestation, and remedial choice.[] These gaps point to the need for benchmarks that test relational understanding and empathy in legally risky contexts, rather than treating affect as a cosmetic add on.

2.2 Implicit Standards and Normative Judgments in Domestic Violence Adjudication
Domestic violence adjudication in China forces courts to translate private narratives into public legal categories. The statutory definition of domestic violence leaves room for judgment, especially when violence is episodic, psychological, or tied to ongoing family roles.[] Discretion then shapes whether violence is legally recognized and whether it is treated as enough to show an irretrievable marital breakdown. That choice often affects divorce, damages, custody, and related remedies. Protection order practice adds another layer. The Anti Domestic Violence Law created a personal safety protection order mechanism, and an application is not contingent upon filing for divorce.[] In later litigation, a prior grant or denial often becomes a practical signal about risk and protectability.[] Typical cases released by the Supreme People’s Court amplify these signals. They also package a court approved moral frame for public uptake.[] Even so, judges do not decide only by matching facts to a rule. They apply implicit standards that are rarely codified as formal elements. Those standards shape whose story is legible and whose fear is treated as reasonable. Empirical comparisons show that the same statutory language can yield different outcomes across local contexts. That variance often tracks different understandings of family stability and social stability. This produces a stable pattern of value laden judgment that operates through legal form. It also functions as social sorting.[]
One recurring cluster concerns persistence and severity. Courts often distinguish ordinary conflict from domestic violence by asking whether conduct looks patterned and whether harm looks serious enough to justify state intervention.[] In protection order cases, isolated incidents are frequently discounted even when some objective proof exists. Severity is commonly operationalized through visible injury or other externally verifiable outcomes. That creates a bias toward physical harm and against psychological abuse unless it produces measurable consequences.[] Typical case narratives reinforce this threshold. They repeatedly emphasize frequency, duration, and escalation as markers of domestic violence. Similar dynamics appear in other systems, where prior history often drives judicial risk assessment.[]
A separate cluster concerns evidence appraisal. Domestic violence is hard to prove because it often occurs in private. Survivors also may lack access to corroborating documents.[] Chinese decisions often reward a complete evidentiary chain. They often discount single source claims, especially when proof is limited to a survivor’s statement or self produced materials. Protection order decisions show the same preference. Medical records and police materials often anchor findings, while gaps in official documentation raise the probability of denial. This institutional preference is not unique to China. Evidence scholarship on civil domestic violence disputes shows how evidentiary rules and credibility heuristics can decide cases before the merits are reached.[] Documentation tied to policing can also shape downstream institutional responses.[]
Another cluster concerns attribution of responsibility and credibility. Courts often rely on implicit expectations about how a credible victim should behave. Work on the ideal victim shows that deviation from expected demeanor can be reframed as unreliability or noncooperation.[] That dynamic is intensified by trauma related inconsistency and survival strategies that look irrational from the outside.[] Chinese practice also shows a partial corrective move. In at least one typical case, the court stated that “delayed reporting aligns with the behavioral patterns of domestic violence victims,” and treated delay as non dispositive.[] Even this corrective can harden into a new template. The risk remains that courts reward the right narrative form rather than the underlying harm.
Public order and good morals form another implicit standard. When violence spills into public space or challenges authorities, courts are more likely to treat the case as socially significant rather than purely domestic. Judges decide against the backdrop of local culture, custom, and material conditions. Those contexts shape how public order and good morals are understood in practice. In settings where family stability is treated as the dominant social good, and where survivors may be economically dependent on the abuser, judges may discount violence and push toward preserving the household. In other settings, courts treat anti violence enforcement as a core part of social stability.[] Public messaging around typical cases also warns against overreading doctrinal moves as broad redefinitions of family. That messaging can shape what the public expects and what courts think they are signaling.[] These implicit standards are the practical target for evaluation. They reveal what legally disciplined empathy looks like in this domain.

2.3 AI Empathy and Social Judgement

LLMs can produce empathic language, but empathic judgment is harder. Human empathy has cognitive, affective, and motivational components. Current systems mainly approximate the cognitive layer through linguistic patterning.[] This matters in domestic violence disputes because the user often seeks recognition and protection, not only polite wording. Institutional settings also push survivors to narrate harm in legible ways, which can distort what a model learns to treat as credible.[] Source attribution changes how empathy is received. Identical content is rated as more empathic and supportive when it is labeled as human rather than AI.[] This gap reflects perceived effort and moral stake. It limits what synthetic empathy can deliver in victim facing support. At the same time, some users apply a machine heuristic and treat AI outputs as more objective than human judgments.[] That perception can lower vigilance toward embedded value choices, which is risky in adjudication adjacent settings.
Cultural contextual intelligence is a distinct bottleneck in China specific domestic violence contexts. Key Conceptions like “guanxi”(relationship), “mianzi”(face), “forbearance” and “family” function as dynamic practices, not stable labels. They involve situational tradeoffs, moral accounting, and strategic restraint. Work on artificial empathy stresses that models do not access the underlying ethical weight of these practices, especially when a term like forbearance can encode shame, sacrifice, and long horizon calculation.[] In domestic violence assessments, a model may treat coping behaviors that reflect face or family duties as inconsistency. It may read them as weak credibility or low urgency. That conversion from culturally shaped survival strategy to adverse inference can create secondary institutional harm.
Bias and accountability risks follow from the same structure. Domestic violence adjudication relies on open textured criteria and value judgments, so model outputs are not neutral. Evidence from judgment settings shows that LLMs can replicate human like biases and can also be pushed by nonevidentiary cues.[] Evidence from generative imaging shows systematic underrepresentation and stereotype reinforcement, even when users expect neutrality.[] When doctrine is vague, the model will default to dominant patterns in training data. That can yield inconsistent value judgments and weak traceability. The absence of genuine moral agency also complicates accountability when harm occurs.[] The practical implication is narrow: improving accuracy alone is insufficient. The harder target is preventing compassion illusion and surfacing value choices that would otherwise hide inside fluent prose.
3 METHODS

Before detailing the workflow, we specify two implementation choices that directly affect internal validity. First, we fix the sampling temperature. Higher temperatures increase output variance and stylistic novelty, but they also reduce doctrinal stability and can amplify hallucinations.[] We therefore use a moderate temperature selected with input from practicing legal experts to balance reasoning richness with reliability. Second, we control for conversational carryover by evaluating each case in a new chat session with identical, standardized inputs. Every run starts from a clean state, so earlier interactions cannot influence later outputs. This improves cross-case comparability and reduces confounds tied to memory and context accumulation. Together, these controls mitigate common LLM failure modes, making it unlikely that residual model artifacts drive our primary results.

3.1 Dataset 

LLMs are increasingly used in value and emotion sensitive settings. Most existing domestic violence datasets still focus on detection and prevalence, not adjudicative judgment. Our benchmark therefore targets decisions where outcomes turn on public morals, relational norms, and discretionary legal standards. We build the dataset from Chinese judicial opinions. Sources include the Supreme People’s Court 2025 anti domestic violence typical cases and the China Judgments Online database.
We sample 108 civil and criminal cases from 2023 to 2025. We prioritize cases with contested narratives, dense reasoning, and detailed party submissions. These features make value balancing visible in the text. Typical cases are especially informative. They are curated to guide lower courts and to show how evidence appraisal and protective measures should be justified in hard scenarios. This setting also fits our research question. Chinese adjudication is a hybrid model. Judges actively examine evidence and clarify facts, while parties still present arguments and contest claims.[] Courts justify outcomes through statutes and also through fairness and social effects when doctrine is open textured. For each judgment, we manually segment the document into background facts, keywords, court reasoning, and disposition. We then de identify and lightly paraphrase the background and outcome. This reduces verbatim overlap while preserving legally material facts and dispute structure. From each case, we write five structured dispute questions. This yields 540 questions in total. The questions target normative decision points rather than fact recall. They cover abuse characterization, risk and persistence, evidence appraisal, victim responsibility attribution, and public morals and relationship context. 

3.2 Prompting Protocol and Language Models

We use a two stage prompting protocol. Stage one generates dispute questions from each anonymized case record. The prompt asks for five structured questions per case. The five questions map to abuse characterization, risk and persistence, evidence appraisal, victim responsibility attribution, and public morals with relationship context. The prompt excludes fact recall and simple yes or no items. It instead requires legal analysis and value judgment that can be traced to the court’s reasoning. A legal expert reviews and edits each question. This step ensures the question targets a real decision point and has a supportable reference answer in the opinion. 
Stage two produces model answers under standardized inputs and sampling controls. Each run starts with a fixed system prompt. Case materials then appear in a stable order. The input includes the de identified background and one structured question. The model is asked to write in a judge style. It must state the governing norms, link norms to facts, and explain how each item of evidence strengthens or weakens each inference. It must also surface value balancing when the legal standard is open textured. We cap generation at 2000 tokens to allow complete reasoning. We also tune temperature to the task. Low temperature supports fidelity and repeatability in legal analysis. Higher temperature supports diversity when generating questions. In our pipeline, we use temperature 0.3 for case analysis, 0.7 for question generation, 0.1 for verbatim text extraction, and 0.5 for comparative analysis. We do not set top k and use API defaults to avoid unnecessary interference with optimized sampling behavior. Each question is tested in a fresh chat session to prevent conversational carryover. We evaluate several representative model families, including GPT 4o, GPT 5, DeepSeek-R1, DeepSeek-V3, Qwen Max, Gemini 2.5 Flash, and Claude Opus 4.

3.3 Evaluation Rubric

Our evaluation rubric mirrors how Chinese courts justify outcomes. It departs from common law designs that emphasize precedent selection and analogical reasoning. Chinese decisions typically start from statutes and high level legal standards. The judge states the governing norm as the major premise.[] The judge then maps disputed facts and issues onto that norm as the minor premise. The disposition follows as a reasoned conclusion. This deductive structure motivates our scoring. It tests whether an LLM can move from abstract norms to case specific judgment in a disciplined way. It also tests whether the model can handle value laden discretion when standards are open textured.
Legal experts score each output on a 0 to 4 scale per dimension. The rubric uses five core dimensions plus error flags and automatic penalties.
	•	Normative basis relevance, i.e., is the invoked statute, interpretation, or other authority operationally relevant and accurate, rather than generic or fabricated?
	•	Subsumption chain alignment, i.e., does the answer connect issue to norm to elements or factors to facts to sub conclusions to final conclusion, without gaps?
	•	Value balancing and empathy alignment, i.e., does the answer identify the right value axes and weigh them in a restrained and professional way, without victim blaming or stigmatizing inferences?
	•	Key facts and issue coverage with evidence mapping, i.e., does the answer capture decisive facts and disputes, distinguish established versus disputed points, and tie each inference to record support without invention?
	•	Outcome and remedy alignment, i.e., is the proposed disposition and relief allocation consistent with the rule fact value chain and functionally equivalent to the reference decision?
	•	Impactful error flags, i.e., are there penalized failures such as hallucinated norms or facts, core misreadings, or harmful value errors that trigger caps and deductions?
Model outputs are sampled across several frontier families, including GPT 4o and GPT 5, DeepSeek V3 via deepseek chat, DeepSeek R1 via deepseek reasoner in thinking mode, Qwen Max, Gemini 2.5 Flash, and Claude Opus 4. All systems run through the same four stage pipeline. Case text is first masked for privacy. Dispute centered questions are then generated from the masked record. Each model produces answers under task adaptive temperature settings. Outputs are finally scored against the judicial decision using the five dimension rubric plus impactful error flags. Annotation proceeds at paragraph level and authority level. Each cited authority is checked for relevance and correct use. Missing or added elements and discretionary factors are recorded, along with any fabricated source, norm, or fact. Expert scoring is costly, so a meta evaluation task is added to test whether LLM graders can track expert judgments. All meta scores remain subject to human audit. The full rubric, threshold caps, penalty rules, and annotated examples are released as part of the benchmark to support reuse and auditability.
4 RESULTS

Across the cases slice, DeepSeek R1 in thinking mode and DeepSeek V3 form the top tier on the total rubric score. Their average totals are 16.45 out of 20 and 16.42 out of 20, with Gemini close behind at 15.63 out of 20. The error profile helps explain the gap. Qwen Max shows the highest count of major errors and obvious errors, which often breaks the norm to fact chain even when the conclusion sounds plausible. Claude is not far behind on obvious errors, which matches the mid level totals. As Fig. 1 shows, the higher-performing models remain strong across normative basis relevance, subsumption chain structure, value and empathy alignment, and key fact and dispute coverage. The lower-performing models lose points on coverage and disciplined linkage, not merely on style.
A separate reliability signal comes from abandoned law references, where lower is better. Gemini shows zero questions with abandoned law citations, while DeepSeek V3 shows one. The rate rises for DeepSeek R1 in thinking mode and Qwen Max at seven each, and it peaks for Claude at ten. The figures also show GPT 4o with the highest abandoned law count in this slice, which tracks its weaker overall rubric performance. This matters because an answer can sound careful and empathetic but still be operationally wrong if it relies on repealed rules. It also exposes a tradeoff inside the DeepSeek. Thinking mode slightly improves average scores, but it increases the risk of outdated authority in this setting. That is a concrete failure mode for value laden adjudication. Legal empathy is not only tone. It requires current, usable law and a traceable chain from norms to facts to relief. The next section unpacks these aggregate patterns at the dimension level, moving from judicial reasoning alignment and explanatory quality to value laden decisions and the impactful errors that most often drive score divergence.

Fig 1. Model Performance Heatmap: Average Scores by Dimension


Fig. 2. Model Rankings by Overall Average Score and Abandoned Law References.  

4.1 Judicial Reasoning Alignment

Normative Basis Relevance. Normative basis relevance measures whether a model selects rules that actually do work in the case. It tests “operational relevance,” not general legal education. In a statute-centered civil law setting, the governing norm functions as the major premise. When the rule is wrong, later subsumption can look fluent but stays ungrounded. The point is not whether the model reaches the “right” outcome. The point is whether the cited authority can support elements, exceptions, or discretionary factors in the way courts use them. In domestic violence characterization, DeepSeek and Gemini often start from the definition clause in the Anti-domestic Violence Law of the PRC, including “ the inflicting of physical, psychological or other harm...” In custody and protection-order disputes, higher scoring answers cite both the child-centered standards in the Civil Code art. 1084, “best interests of the minor” and art. 1085, support payments and the protection-order gateway norms ( Anti-domestic Violence Law, arts. 23 and 27, “personal safety protection order” “人身安全保护令”). In divorce, property, and damages, Qwen-Max and Gemini are most reliable when they map each claim to the corresponding article, such as divorce grounds, property division, housework compensation, and divorce damages. In homicide cases triggered by long-term abuse, DeepSeek’s better answers separate conviction from sentencing and cite the crime definition and surrender mitigation (Criminal Law of the PRC, art. 232 and art. 67). One representative answer makes the sentencing move explicit: “recommend a substantial mitigation within the sentencing range for intentional homicide, but not a downward adjustment to the next range.” This citation pattern matches what judges treat as legally “actionable” in their written reasons.
Besides, failure cases are rarely random. They reflect a structural gap between model citation habits and judicial discretion. A common miss is slogan-level reliance on broad principles. DeepSeek sometimes frames disputes with the Civil Code art. 8 “public order and good morals” and art. 153 “void juridical act.”, yet it does not connect them to the court’s operative tool, such as intent-interpretation rules in a waiver or settlement setting. One typical phrasing is: “legal protection of personal rights is the cornerstone of social order,” which sounds normatively appealing but can miss the judge’s technical path. Another recurring weakness is thin procedure and evidence law. Complex fact patterns often turn on burden allocation and proof rules under the Civil Procedure Law, including the baseline “who asserts, who proves” (Civil Procedure Law of the PRC, “谁主张，谁举证”), yet many LLM answers stay on entity law only. Norm mixing is another source of low scores. Qwen-Max occasionally cites the marital community-property rule in a cohabitation case (Civil Code of the PRC, art. 1062 “marital joint property”), then tries to walk it back. That starting point still distorts the legal frame. Claude sometimes omits the decisive gift rule when “gift” is the disputed label (Civil Code of the PRC, art. 657 “gift contract”). Update lag also matters. For bride price disputes, answers that cite older interpretive anchors instead of the newer SPC bride price provisions lose “operational” precision (SPC Provisions on Handling Bride Price Disputes, arts. 5–6《最高人民法院关于审理涉彩礼纠纷案件适用法律若干问题的规定》). Finally, some judgments draw on international norms to signal protective orientation. Models rarely mirror that layer, such as CEDAW-related guidance (The Convention on the Elimination of all Forms of Discrimination Against Women), which reduces completeness when the decision itself uses it as a legitimating frame.
These patterns explain why normative basis relevance is a structural marker of judicial alignment. It is also a legitimacy proxy. Public acceptance of AI legal support can be high, even when it is explicitly non-human. [] In this benchmark, high scores come from disciplined rule selection and function-aware citation. Low scores come from generic principles, domain mismatches, missing procedural anchors, and stale or omitted controlling sources.

Subsumption Chain Alignment. The strongest outputs treated legal labels as propositions that must be proven, then forced themselves through factorization and mapping. DeepSeek did this well in a domestic violence framing task. It began with the dispute issue, whether the victim’s conduct is better characterized as improper provocation or domestic violence as victim fault. It then stated a norm under Anti-domestic Violence Law, art. 2, and broke “domestic violence in the legal sense” into three working parts such as a control like harmful act, a causal link to the offense, and a proportionality threshold tied to urgent safety risk. It then mapped concrete facts into each part, including long term verbal abuse and control, property destruction at the scene, a slap, and the knife stabbing directed at a sofa. It marked key items as not satisfied with reasons that track a judge’s review logic, such as the knife act targeting property, the record not supporting homicidal intent, and the sequence looking like retaliation rather than a direct response. The sub conclusion, not domestic violence in the legal sense, followed from those itemized judgments rather than from rhetoric.
The same disciplined structure appeared when models used court like sequencing in defense and protective relief contexts. DeepSeek often used the recognizable two stage path for legitimate defense: whether legitimate defense is established, then whether it is excessive, and it operationalized Guiding Opinions, art. 10 (《指导意见》) as testable factors. It tied factors to specific record facts such as a large power gap, one successful knife seizure, a later sequence of 17 stabs, and post event statements, and it explained why each factor was met or not met before issuing a sub conclusion. Gemini showed a parallel strength in protection order cases by linking Anti-domestic Violence Law, art. 2 and art. 23 to a structured realistic danger analysis. It did not stop at “there is danger.” It broke danger into record facing risk factors, then grounded them in facts such as self harm with a knife reflecting escalation, pushing the applicant down causing injury reflecting direct physical intrusion, and repeated conflict reflecting recurrence. Custody disputes showed the same pattern when Qwen and GPT operationalized Civil Code of the PRC, art. 1084 through factors like stability, caregiving history, the child’s expressed preference, parental conditions, and conduct risk, and then anchored each factor in adjudicated facts such as long term residence with the mother and schooling near the mother’s home. Remedy analysis also aligned better when Qwen separated claims into distinct sub chains and tied each to its own norm, including divorce under Civil Code art. 1079, property division and homemaker compensation under art. 1087 and art. 1088, and damages under art. 1091.
Weaker outputs clustered around a few recurring failure types. First is norm drift or value substitution. In the settlement waiver example, DeepSeek relied on “public order and good morals” as the main engine, but the judge’s operative path was about intent interpretation through text, context, and a sequence of acts like the written “no pursuit” statement, the parties not divorcing at the time, the presence of a child, and later reaffirmation in divorce mediation. When the model swaps the court’s working norm for a higher level principle, its element mapping no longer aligns even if the bottom line matches. Second is element omission around mental violence and control. Several answers treated self harm threats as simple knife threats, without breaking mental coercion into fear induction, control purpose, and intrusion on mental peace, which is often the judge’s internal route. Third is issue drift. One Qwen chain pivoted to the victim’s legitimate defense and cited Criminal Law of the PRC, art. 20 (《中华人民共和国刑法》), then concluded no victim responsibility, but the dispute issue was the alleged abuser’s responsibility and whether the self harm threat supports protection order relief under Anti-domestic Violence Law art. 2 and art. 23. A closed chain that answers the wrong question is still misaligned. Finally, we also saw thin mapping where models listed the right factors but did not perform itemized satisfaction judgments against the appellant’s key defenses, as in some bride price disputes citing Civil Code art. 1042 and SPC Interpretation I art. 5 and art. 31 (《最高人民法院关于适用<中华人民共和国民法典>婚姻家庭编的解释（一）》). The factor list looks complete, yet it misses the rebuttal driven steps that courts use to justify disposition.

4.2 Explanatory Quality and Legal Application

Key Facts and Issue Coverage. A legally usable output has to do three things at the same time. It must identify the facts that truly drive the outcome, connect those facts to the relevant legal elements or discretionary factors, and maintain strict evidential discipline. The goal is to control fact status. DeepSeek performed well in the self defense style dispute. It captured the long term conflict background, including frequent insults and slaps, economic pressure, and social isolation. It then tracked the incident day escalation, including property damage, the police call, renewed quarrel after return, “stabbing the sofa,” the verbal trigger “you should die,” and the struggle into the corridor. It also captured the defendant’s conduct, “seizing the knife” and “stabbing 17 times,” plus physical asymmetry between the parties. The strength lay in disciplined linkage, not storytelling. DeepSeek treated “stabbing the sofa” as a legally relevant fact for intensity or immediacy, and treated long term insults and control as inputs to evaluating infringement intensity and control related factors. A second strong example refined the same method by isolating a decisive micro fact and stating its doctrinal consequence. It stressed that “all evidence indicates the knife’s direction was toward the sofa, not the defendant’s body,” then placed that fact into a structured frame tied to unlawfulness intensity, imminence, necessity, and intent transformation. This is record based legal application, the facts function as inputs to tests.
On one hand, Strong performance also appeared in family cases when outputs treated the judgment as a proof structure. DeepSeek did this in a divorce reasoning example by covering marriage duration, children, procedural history, and the claimed grounds such as emotional breakdown, domestic violence, rape related history, and separation, while separating what the court treated as established, such as a rape conviction history, from what remained disputed or unproven, such as continuing domestic violence or persistent separation, and mapping these into the breakdown factors and discretionary balancing the court actually used. In a protection order setting, Claude performed strongly by capturing the parties’ relationship, the victim’s economic dependence as a full time homemaker, repeated domestic violence, and that the last incident had police involvement and medical proof, then mapping violence facts to the legal recognition of domestic violence and mapping economic dependence to its distinct legal relevance for compensation and responsibility. In custody modification and protection contexts, Qwen performed well when it captured the custody background, the father’s long term absence for work, the child’s living arrangement with grandmother and uncle, the harm facts including beatings and risk of sexual abuse, and the evidence anchors like injury appraisal and the child’s letters, then mapped those facts into protective duties under the Anti-domestic Violence Law and the Law of the People's Republic of China on the Protection of Minors (2024 Amendment). Gemini also performed well in another domestic violence context by clearly separating party assertions from judicial findings. It treated the workplace “slap” incident and the supporting materials as evidence to be weighed, while correctly noting that the trial court’s domestic violence finding was affirmed on appeal, and then mapping those facts to the legally relevant violence and proof structure.
On the other hand, weak outputs cluster into repeatable legal failure types. Evidential defaulting appears when an answer treats one side’s story as proven. On one of the cases, DeepSeek built its analysis almost entirely on the applicant’s asserted facts and evidence, implicitly assuming chat logs and injury photos proved the claim. The court’s decisive point was the opposite and the evidence “could not achieve the purpose of proof.” Because that dispositive evidential status was omitted, the later subsumption became doctrine applied to an imagined record. A related inference inflation shows up in Claude, which introduced “economic control” as a case fact even though the materials did not establish restrictions on economic autonomy, reasoning instead from “common patterns” and financial context. Another failure is facts are listed but assigned the wrong legal meaning. In a protection order dispute, Claude captured “self harm threats with a knife” and “pushing leading to injury” yet reframed the case as bodily harm and failed to treat the knife based self harm threat as the decisive act for psychological violence. The judgment’s core was that the husband did not directly beat the wife, but the knife threat caused fear and constituted psychological violence. GPT showed a parallel mapping weakness by capturing the knife threat and injury but under emphasizing the separate psychological fear finding that the judgment treated as an independent basis for domestic violence recognition.
Focus drift is also common. In an appellate custody case, GPT focused on domestic violence recognition and imported facts like slapping and evidence media even though the appellate court had already confirmed domestic violence and set the only live issue as custody allocation. GPT then failed to cover the decisive custody facts, including that the children had lived with the mother for nearly three years after separation, attended school near the maternal family with a stable environment, the court asked the daughter’s preference and she wanted to live with the mother, and geographic distance would impose major environment change costs. A parallel drift pattern appeared in Gemini, where the answer accurately summarized domestic violence facts but still analyzed whether domestic violence was established even though the appellate decision framed custody as the only live dispute. In a separate case, Gemini’s fact summary was directionally right but showed a minor timeline imprecision, treating “formal case filing” as occurring before an asset transfer when the record sequence was tighter.
Besides, procedural posture omissions are uniquely damaging. This appeared in DeepSeek in retrial review contexts, where the output summarized the applicant’s retrial claims and mapped them into substantive elements but omitted that the applicant did not appeal within the statutory period without justification and provided no new evidence in retrial review. Similar “missing the dispositive factor” problems appeared in Qwen in a betrothal gift return dispute, where the answer captured the gift amount and short cohabitation but omitted contested fault allegations such as domestic violence and lack of support during miscarriage that the court used to set the return ratio, and it also omitted the woman’s new appellate request about a gold ring. Another example is Qwen in a funds dispute, where the output captured transfers but over centered “improper relationship” and failed to integrate the offsets and net difference calculation system the court actually used, even though that calculation was the core basis for “no legal basis” reasoning. These are not missing details. They are missing the facts that drive the legal conclusion. 
Outcome and Remedy Alignment. LLM outputs may look more stable than human decisions because they lack intrinsic human variability.[] Yet stability is not the same as legal alignment, especially when the remedy is multi layer and operational. Several outputs showed high quality alignment. Although in some homicide cases, DS tracked the court’s direction and its sentencing logic. It agreed with rejecting a domestic violence finding, while still treating the victim’s role in escalation as relevant mitigation. It treated confession as a key leniency factor. Functionally, that matched a life imprisonment disposition and signal severe punishment calibrated by mitigation. DS also aligned its aggravating factors, such as brutality and severe consequences, and its mitigating factors, such as surrender, remorse, victim contribution, family conflict trigger, and compensation and forgiveness, with the court’s actual considerations. DS also aligned well when the remedy structure was hybrid and task specific, not purely monetary. In a case involving both a personal safety protection order and custody change, DS recommended immediate issuance of a protection order and included standard prohibitions such as no violence and no harassment and no contact, plus a move out measure tied to cohabitation risk. The court issued a six month prohibition package. The core relief, a strong no contact prohibition regime, was functionally equivalent.
Monetary relief alignment was also strong where models kept remedy components tied to proven losses and legal duties. DS explicitly supported the court’s economic compensation items such as medical expenses, lost wages, nutrition, nursing, and property loss, and it supported non economic accountability such as apology, while treating calculation and allocation as reasonable. The structure mattered more than precision. The model endorsed the same categories of relief and justified them through its own prior legal analysis without internal conflict. In divorce and domestic violence settings, Claude showed strong outcome and remedy type alignment. It endorsed granting divorce, recognizing domestic violence, tilting property division toward the victim, awarding divorce damages, and awarding domestic labor compensation. It did not provide a numeric split, but it matched the court on the remedy architecture. In marital debt litigation with a domestic violence context, GPT’s remedy suggestions, such as re examining debt character, accounting for domestic violence context, and placing the burden on the creditor, were functionally aligned with remand or reversal paths. 
In a custody change case, Qwen matched the direction and the key relief allocation. It recognized domestic violence, supported custody change to the mother, and treated continued protection order enforcement as necessary. It also linked child mental health to relief design by recommending counseling and treatment, matching the court’s emphasis that the father failed to address the child’s diagnosis and caused secondary harm. Gemini matched the direction by recognizing domestic violence, rejecting victim responsibility, and supporting protective orders. It then proposed a set of linked measures such as strict protection order enforcement, civil compensation, divorce litigation, criminal liability assessment, attention to children, and perpetrator intervention. The court’s remedy path was operational and multi agency, including service and warning, coordinated monitoring and support, fines and admonition, shelter provision, mediated divorce, and attention to minors’ mental health. Gemini’s package was functionally equivalent in purpose and structure because both implement a layered response that moves from immediate protection to accountability and longer term stabilization. 
However, misalignment often shows up in the remedy layer even when the overall direction is plausible. In the homicide case, DS sometimes predicted death with a two year reprieve (死刑缓期二年执行) rather than life imprisonment (无期徒刑). Both reject immediate execution and sit within a realistic sentencing range, but they are not the same legal form. The difference matters because they diverge in legal status, execution mechanics, and later commutation pathways. Importantly, DS’s own mitigation chain pointed toward leniency. A recurring weakness is remedy thinness in cases where the court’s relief is a system rather than a single order. In a protection order case, Claude aligned on issuing the protection order but did not reflect the court’s closed loop design. The court paired issuance with service and warning, multi agency coordination, ongoing monitoring, sanctions for violations such as fines, and shelter support. Claude largely stopped at rapid issuance and did not integrate enforcement, supervision, violation consequences, or coordinated protection for the victim and minors. The direction was right, but the remedy was not functionally equivalent to what the court actually built. The same thinness appeared in GPT. In one protection order setting, GPT supported maintaining the order and suggested mediation and monitoring, yet it did not match the court’s layered mechanism that included fines, admonition, shelter provision, and child focused measures that ultimately supported a mediated divorce. This gap is practical, not stylistic, because it changes how the remedy operates.
Remedy drift also occurs when issue drift prevents the model from landing on the court’s decisive allocation. In an appellate custody dispute, Claude offered a defensible sub view that a single physical friction episode may not, by itself, constitute legal domestic violence. That stance was not necessarily inconsistent with the court, because the court did not treat domestic violence as the deciding axis. The failure was at the remedy endpoint. The court’s key relief was custody allocation, resolved by affirming custody with the mother based on stability and welfare factors. Claude’s remedy section stayed abstract and did not produce a clear custody allocation outcome that matched either its own reasoning or the court’s disposition. This captures the core risk in this dimension. Legal characterization alone is not enough unless it translates into a concrete relief allocation.
More serious misalignment appears as outcome reversal, where the proposed remedy architecture conflicts with the reference judgment direction. In property division, DS treated domestic violence as the central driver and proposed a materially greater than half share for the wife, with concrete adjustments such as using actual sale price for an office building, sharply tilting housing proceeds, and scrutinizing equity transfers. The court did the opposite. It dismissed the appeal and maintained equal division, citing procedural limits and rejecting the appellant’s reasons. DS’s chain may be coherent in isolation, but it fails direction and relief alignment against the reference. Reversal risks are amplified in retrial and rehearing contexts, where the remedy question is often procedural before it is substantive. Qwen recommended rehearing and implied the original judgment was wrong, while the court dismissed the rehearing application. A similar reversal occurred when DS proposed revising the judgment to support mental distress damages, while the court dismissed rehearing based on evidence insufficiency and the absence of appeal or new evidence. In these settings, remedy alignment depends on procedural posture. If a model overlooks or discounts procedural bars, it can generate a coherent substantive package that still conflicts with the adjudicative path the court legally must follow.
Another recurring weakness is over weighting a factor that the court treated as one circumstance among many. In a betrothal gift return dispute, Gemini argued that conduct should be explicitly labeled as domestic violence and used as a major lever to change the return amount. The court treated the injury event as one factor within a broader balance and still set a high return ratio. Gemini’s proposed relief structure elevated domestic violence into a decisive adjustment, which was not functionally equivalent to the court’s balancing design, even if the moral intuition was understandable. Where the remedy is relatively simple and the record points to a clear endpoint, such as granting divorce, changing custody, or excluding a debt from marital liability, LLMs often track the correct direction and core relief categories. Where relief is multi layer, operational, or procedurally constrained, alignment becomes fragile. 

4.3 Value Laden Decisions 

Unlike math or logic tasks where conclusions follow from facts, judicial writing often turns on normatively charged and open textured terms such as reasonable, substantial emotional distress, or ambiguous statutory language that admits multiple readings. This dimension therefore tests whether models can surface the correct value axes and keep empathy professional, while avoiding victim blaming, stigmatization, or moralized inference. Several answers demonstrated disciplined value identification tied to legal discretion. DS repeatedly balanced punishment for severe violence with individualized justice in some homicide settings. It stressed social safety and the sanctity of life, but also treated family conflict as context. DS used restrained language like “long term improper words and conduct” and “direct responsibility for escalation,” while still rejecting the move from context to justification. It also separated “victim responsibility” from the legal predicates of self defense, which reduced the risk that empathy becomes a back door to rationalizing violence. In the self defense style dispute, DS framed the value boundary as encouraging legitimate defense while preventing abuse. That framing matters because it preserves the integrity of the defense while remaining sensitive to escalation risk. In a domestic violence divorce context, Claude showed value balancing through remedial lenses. It treated compensation as dignity repair and weak party protection, and it stated that “economic dependence does not reduce responsibility” but instead supports remedial tilt. It endorsed domestic work compensation and divorce damages under Civil Code Article 1091 and kept the tone non sensational. In child related cases, Claude, GPT, and Qwen consistently operationalized best interests into concrete concerns. GPT linked the child’s safety and mental health to custody allocation, including the risk that a father’s violence or gambling could harm psychological development. Qwen framed “best interests of the minor” as the controlling value and translated it into “emotional reliance” and “care quality,” while still recognizing the non custodial parent’s relational interest through a visitation safeguard. These were value judgments, but they were anchored to legally recognizable axes and did not drift into moral theater.
Some outputs also appeared outside the domestic violence core, where the value axis is often public order plus procedural fairness. In a family funds or intra family transaction dispute, Gemini balanced rule of law predictability with family ethics and ordinary life logic. It insisted that basic contract elements and proof burdens cannot be displaced by broad principle talk, while still acknowledging the special context of elder to younger transfers and caregiving expectations. The key is that Gemini did not turn family morality into blame. It avoided stigmatizing either side and treated family norms as interpretive context for intent. DS showed a similar style in cohabitation property disputes. It resisted a mechanical ownership story and instead tied “building a shared home” to substantive fairness. At the same time, it protected the internal stability of co ownership by noting that one co owner’s use is not automatically an unlawful obstruction. DS also used procedure as a value axis in property fairness cases. It framed judicial economy and dispute finality as reasons to require partition first, then property claims. This kept empathy from becoming a shortcut around process. In another property setting where a party raised domestic violence allegations in a possession style suit, DS balanced two values without collapsing them. It took domestic violence seriously as a rights issue, but it also defended evidence based adjudication and warned against opportunistic, unproved accusation as a threat to procedural legitimacy. That is risk sensitivity, the critique targets litigation strategy and proof posture, not the moral worth of the claimant.
Empathy quality varied in a way that mirrors institutional legibility findings in domestic violence scholarship. Sweet (2019) shows that in the United States, emphasizing mental health impacts and recovery can make survivors institutionally legible.[] The comparative concern is that courts can marginalize survivors with mental disabilities. In the model answers here, empathy was sometimes warmer than the court’s framing. GPT and Qwen explicitly treated child psychological harm and fear as legally relevant, rather than as background emotion. Gemini also handled a hard tension case by separating compassion from doctrinal distortion. It acknowledged hardship and vulnerability, but insisted that loss filling in tort cannot be converted into general welfare redistribution. It pointed instead to social security as the proper channel. That is empathy with boundary discipline. At the same time, this dimension exposes a risk of algorithmic trauma. If a model learns that only the most narratively legible victim deserves protection, it can reproduce a rational victim template. The best answers avoided that by tying trauma language to legal functions such as risk assessment, dignity protection, and child welfare, rather than to moral deservingness. Some answers were not overtly biased, but their value architecture was thin or incomplete. In a protection order case with self harm threats, Claude and GPT often identified safety and speed, but they did not reach the deeper axis that the court foregrounded. The court treated coercive “control” as the essence of domestic violence and treated mental fear as a substantive harm, not a secondary effect. It also framed multi agency coordination as social governance value and highlighted minors as an independent protection axis. LLMs sometimes remained at “protect first” level. That made the value discussion slogan like. A similar pattern appeared in Qwen on a high bride price case. The court balanced respect for customary practice with a clear normative stance against excessive bride price, and it integrated miscarriage and injury as discretionary compassion factors. Qwen largely stayed in rule application and missed the court’s explicit public order messaging. In fake divorce avoidance contexts, Claude also tended to under state the court’s strong emphasis on maintaining the seriousness of the marriage registration order. 
Across LLMs, the more reliable outputs treated values as constraints that shape discretion and relief. They did not treat empathy as sentiment. They treated it as professional recognition of risk, dignity, and vulnerability that must still pass through proof, procedure, and legal categories. When outputs became generic, the problem was not tone. The problem was that key value axes like coercive control, minors’ welfare, procedural posture, or public order signaling were not identified or were not carried through into the legal recommendation.

4.4 Impactful Errors 

Impactful errors are not cosmetic, they change legal authority, proof posture, or the court’s available relief. Law requires institutionally valid reasons, not fluent proxies. When models optimize for “citation shaped” language, they can land on locally plausible text that is globally wrong, which fits the problem of deceptive search spaces and unintended side effects. Across models, stale law was a repeatable moderate error. Several answers cited the expired Marriage Law instead of the Marriage and Family Book of the Civil Code. It is a live law mistake. The problem is sharper when the model itself signals the effective regime. GPT cited “Supreme People’s Court Interpretation on the Application of the Marriage and Family Book of the Civil Code (II)” (《最高人民法院关于适用〈中华人民共和国民法典〉婚姻家庭编的解释（二）》), yet still leaned on the abolished “Marriage Law.” In the same category, some answers missed key Civil Code anchors such as Civil Code Article 1088 on housework compensation, or should have used Civil Code Article 1084 as the core custody standard.
Citation accuracy errors ranged from moderate to major. Moderate errors included wrong article numbers with roughly correct doctrine. Claude cited “Civil Code Article 1074” where the content matched Civil Code Article 1091 on divorce damages. It also cited “Civil Code Article 1063” where the content matched Civil Code Article 1088. This does not automatically flip outcomes, but it breaks traceability and raises review cost. Gemini cited Civil Code Article 1092 in a custody dispute even though Article 1092 targets concealment or dissipation of marital property. That is a clear relevance error, which also makes the citation ineffective. GPT cited Civil Code Article 154 on public order and good morals but did not use it to analyze whether the “fake divorce” conduct violated public order. A cite that does no work signals ornamental reasoning. 
Fabricated authority is a major error because it manufactures constraints. Qwen cited a nonexistent SPC document, “Opinions of the Supreme People’s Court on Trying Civil Cases Involving Domestic Violence” (《最高人民法院关于审理涉及家庭暴力的民事案件若干问题的意见》). A court cannot verify it. This is high risk because it looks like law while being fiction, which is a classic inner alignment failure pattern. Misquoting a real statute can also be high impact when it shifts the test. Claude misquoted Anti-domestic Violence Law Article 2 by inserting terms like “kidnapping” and “confinement,” and it also framed the protection order dispute as bodily harm logic when the judgment treated the knife based self harm threat as psychological violence producing fear. That mapping error can redirect the relief logic. In addition, core fact inversion is major because law is proof based. GPT repeatedly stated evidence was “not cross examined” or “not effectively cross examined,” while the judgment recorded the evidence “was cross examined” and the opposing party had “no objection.” That single inversion corrupts probative force analysis from the start. 
Procedural stage confusion is outcome shifting in retrial contexts. Gemini recommended “vacate and remand” at the retrial review stage, even while citing Civil Procedure Law Article 215 (《中华人民共和国民事诉讼法》), which points the review court toward rejecting the retrial application when statutory grounds are not met. Mixing “review” with “retrial on the merits” changes the court’s power set, so the remedy becomes legally unusable even if some substantive discussion is sensible. The common thread is that legal errors are not equal. Some errors are low-stakes and easy to repair with editing. Others cut into the norm-to-fact chain, especially when citations are wrong or the cited law is outdated. The most serious failures should be treated as hard fails, including fabricated authority, inversion of core facts, and confusion of procedural stage. 
5 CONCLUSION

Domestic violence is pervasive and multi causal, so early, accessible guidance can reduce harm even before formal proceedings begin. Our benchmark, DVJUSTICE, suggests that large language models can meaningfully support domestic violence users at the consultation stage, especially through clear safety oriented guidance, restrained reassurance, and legally framed next steps. In our sample, the stronger systems treated values as constraints on discretion and relief, and they surfaced axes like risk, dignity, vulnerability, minors’ welfare, and procedural posture in a way that can help users understand what courts are likely to treat as legally salient. This “cognitive empathy” can also increase institutional legibility for survivors, which socio legal work shows is often decisive in whether harm is recognized and acted upon.[] At the same time, perceived empathy from a chatbot is not equivalent to human care, the correct role is augmentation rather than emotional substitution. This framing is consistent with access to justice work. AI can reduce the legal advice desert by offering low cost orientation and document triage, but it should not be treated as an end to end lawyer or decision maker.
The same evidence also shows why these tools must not be used as outcome engines or as substitutes for judges. Impactful errors were not cosmetic. They changed the governing law, proof posture, or available relief, including repeated reliance on the repealed “Marriage Law” instead of the Civil Code Marriage and Family Book, and even fabricated authority. These failures track a deeper alignment problem: models can generate locally plausible legal text while drifting from institutionally valid reasons, especially under deceptive search spaces and proxy objectives. Even when the direction is compassionate, the model can misstate legal form and procedure, for example by confusing “death penalty with a two year reprieve (死刑，缓期二年执行)” with “life imprisonment (无期徒刑),” or by proposing reopening remedies that the procedural posture legally forecloses. 
Property division is an especially high risk zone because small legal missteps can materially change distribution effects and compliance incentives, so helping the victim cannot replace proof rules and the court’s remedial architecture. This gap also explains a recurring tension that lay observers often feel. A reader may think divorce “should” be granted or the victim “should” win, yet judges may deny divorce or refuse an evidentiary upgrade because they must protect legality, procedural limits, and the public meaning of adjudication, which in China is also shaped by a state centered harmony frame where “family building” is tied to national development and social harmony. In practice, models can reflect a plain moralized caretaker instinct that overshoots the court’s legally bounded rationality, which is precisely why they should assist, not adjudicate. 
Methodologically, our rubric and cross model testing offer a grounded baseline for upgrading legal LLMs in value loaded disputes, and for designing multi model collaboration. The practical promise is therefore institutional, not utopian. LLMs can act as scalable junior colleagues for triage, summarization, and risk flagging, helping courts and practitioners manage pressure without importing human emotional burden into every micro decision. The normative boundary remains firm. Legal authority must stay with accountable human decision makers, while AI is positioned as a disciplined assistant that expands access, reduces delay, and supports legally justified care in domestic violence disputes. 
6 LIMITATIONS

While our benchmark provides a structured way to test how LLMs reason about domestic violence disputes in China, several limitations warrant discussion. First, the benchmark is built on Chinese written judgments rather than full case files. Judgments present a court curated narrative. They compress timelines, filter contested details, and often omit key process steps. This can overstate model readiness for real consultations, where survivors often provide fragmented facts and incomplete proof. It also constrains what can be inferred about risk assessment and enforcement, which may depend on information that never appears in the final decision.
Second, the dataset is jurisdiction and period specific. Most cases come from the post Civil Code era and from courts operating within a policy environment that links family governance to social harmony. The resulting patterns may not generalize to earlier periods, to other provinces, or to legal systems with different evidentiary baselines and remedial toolkits.
Third, the benchmark measures textual adequacy rather than functional protection. A model may recommend a protection order yet miss the closed loop architecture that makes relief work. Courts often rely on service, warnings, multi agency coordination, ongoing monitoring, sanctions, and access to shelters. The framework can flag remedy thinness in the written output. It cannot observe execution quality or whether institutions actually deliver the package. This limitation is especially salient in domestic violence governance, where enforcement determines whether relief is symbolic or safety producing.
Fourth, the benchmark does not resolve deployment and governance risks. LLMs do not hold judicial discretion, fact finding authority, or public accountability. In domestic violence settings, automation can shift responsibility and invite outcome driven shortcuts under caseload pressure. Data fragmentation across courts, police, shelters, and community organizations further constrains any system that depends on timely coordination. These institutional constraints shape what an AI system can safely do, even when the text appears well aligned.
Fifth, the benchmark is built on Chinese language materials and does not directly test cross lingual performance. The same model may behave differently when prompted in English versus Chinese, especially on culturally loaded concepts and procedural terms. Future work should include bilingual prompts and parallel evaluation to measure whether translation and framing shift norm identification, value balancing, and error rates.

